import cProfile
from concurrent.futures import ThreadPoolExecutor
import json
import multiprocessing
import os
from pathlib import Path
import subprocess
from time import sleep
import time
import traceback
from bs4 import BeautifulSoup
import numpy as np
from augraphy import AugraphyPipeline
from unoserver import client
import requests
from tqdm import tqdm
from PIL import ImageDraw
import cv2 
import threading

import src.utils as utils
from src.augmentations import get_augmentation_phases
from src.docx_document import DocxDocument


def profileit(func):
    def wrapper(*args, **kwargs):
        datafn = func.__name__ + ".profile" # Name the data file sensibly
        prof = cProfile.Profile()
        retval = prof.runcall(func, *args, **kwargs)
        prof.dump_stats(datafn)
        return retval

    return wrapper

class DocumentGenerator:
    def __init__(self, max_threads, image_size, docx_config, out_folder, port, uno_port):
        self.max_threads = max_threads
        self.image_size = image_size
        self.out_folder = out_folder
        self.docx_config = docx_config
        self.port = port
        self.uno_port = uno_port
        
        self.image_counter = 0
        
        self.debug_mode = True

        command = f"/usr/bin/python3 -m unoserver.server --port {port} --uno-port {uno_port} > /dev/null 2>&1"
        print('START SERVER', port, uno_port)
        self.unoserver_process = subprocess.Popen(command, shell=True)
        self.uno_client = client.UnoClient(port=port)
    
    def __del__(self):
        self.unoserver_process.kill()

    def generate(self, urls):
        print('Start Document Generator...')
        with ThreadPoolExecutor(max_workers=self.max_threads, 
                                thread_name_prefix=f"{multiprocessing.current_process().name}_thread") as executor:
            futures = [executor.submit(self.create_doc_try_except, url) for url in urls]
            for future in futures:
                future.result()
    
    def create_doc_try_except(self, url):
        try:
            self.create_doc(url)
            print(f'{threading.current_thread().name} total images generated by the current process: {self.image_counter}')
        except Exception as e:
            print(traceback.format_exc())

    #@profileit
    def create_doc(self, url):
        doc = DocxDocument(self.docx_config, self.uno_client)
        response = requests.get(url)
        if response.status_code != 200:
            print(f"Bad Response: {response}")
            return
        
        # create colored docx document
        soup = BeautifulSoup(response.text, 'html.parser')
        for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', "table"]):
            if element.name.startswith('h'):
                doc.add_heading(element)
            elif element.name == "table":
                doc.add_table(element)
            else:
                doc.add_text(element)
                
            if doc.get_num_words() > self.docx_config["max_words"]:
                break
            
        # extract annotations from colored images
        colored_images = doc.get_images(dpi=200, image_size=1500)
        annotations = self.get_bboxes(colored_images, doc.color2word)  # bboxes are normalized to [0,1]
        doc.convert_to_uncolored_docx()
        images = doc.get_images(dpi=200, image_size=1024)  # get images for augmentation stage        
        for i, image in enumerate(images):
            if len(annotations[i]['words']) != len(annotations[i]['bboxes']):
                continue
            # unnormalize bboxes to augmentation image size
            bounding_boxes = np.array(annotations[i]["bboxes"])
            bounding_boxes = utils.unnormalize_bboxes(bounding_boxes, colored_images[0].size[0], colored_images[0].size[1])

            # perform augmentation
            augmentation_pipeline = AugraphyPipeline(bounding_boxes=bounding_boxes,
                                                     log=False, **get_augmentation_phases())
            augmented_cv2, _, _, augmented_bounding_boxes = augmentation_pipeline(np.array(image))
            with threading.Lock():
                if self.debug_mode:
                    utils.draw_bboxes(image, augmented_bounding_boxes, annotations[i]["words"])
                    utils.draw_bboxes(colored_images[i], augmented_bounding_boxes, annotations[i]["words"])
                    colored_images[i].save(self.out_folder / f"im_{self.image_counter}_colored.png")

                # resize image to final dataset size and save 
                augmented_cv2 = cv2.resize(augmented_cv2, (self.image_size, self.image_size))
                cv2.imwrite(str(self.out_folder / f"im_{self.image_counter}.png"), augmented_cv2)
                
                # convert booxes to (x, y, w, h) format and normalize to [0,1]
                augmented_bounding_boxes = np.array(augmented_bounding_boxes).astype(int)
                width, height = image.size
                annotations[i]["bboxes"] = utils.normalize_bboxes(augmented_bounding_boxes, width, height).tolist()

                # save annotation
                with open(self.out_folder/ f"im_{self.image_counter}.png.json", "w") as f:
                    json.dump(annotations[i], f)
                self.image_counter += 1       
  
    def get_bboxes(self, images, color2word):
        annotations = []
        for image_pil in images:
            width, height = image_pil.size
            image_annotations = {"words": [], "bboxes": []}
            image = np.asarray(image_pil)

            thr = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            thr = cv2.threshold(thr, 254, 255, cv2.THRESH_BINARY_INV)[1]
            cnts = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]

            for c in cnts:
                peri = cv2.arcLength(c, True)
                approx = cv2.approxPolyDP(c, 0.015 * peri, True)

                if len(approx) == 4:
                    x, y, w, h = cv2.boundingRect(approx)
                    rgb_color = image_pil.getpixel((x+1, y+1))
                    color = '#%02x%02x%02x' % (rgb_color)
                    if color in color2word:
                        word = color2word[color]
                        image_annotations['words'].append(word)
                        image_annotations["bboxes"].append(
                            (
                                x / width, 
                                y / height, 
                                (x + w) / width, 
                                (y + h) / height)
                             )
            annotations.append(image_annotations)
        return annotations
